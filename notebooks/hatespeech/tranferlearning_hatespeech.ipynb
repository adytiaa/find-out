{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "Words in index: 22101\n\n Evaluation of model with ALL layers fine-tuned:\nWARNING:tensorflow:From /home/tcake/coding_projects/python/opt_out/find-out/find-out/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/tcake/coding_projects/python/opt_out/find-out/find-out/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "\r  32/2982 [..............................] - ETA: 3s",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1024/2982 [=========>....................] - ETA: 0s",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1760/2982 [================>.............] - ETA: 0s",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2720/2982 [==========================>...] - ETA: 0s",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2982/2982 [==============================] - 0s 72us/step\n",
      "acc: 87.42%, loss: 0.34\n",
      "Confusion matrix:\n[[2181  139]\n [ 236  426]]\nMarco F1:0.807606\nMicro F1:0.874245\nWeighted F1:0.870562\n\n Evaluation of model with LAST layer fine-tuned:\n",
      "\r  32/2982 [..............................] - ETA: 4s",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1344/2982 [============>.................] - ETA: 0s",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2400/2982 [=======================>......] - ETA: 0s",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2982/2982 [==============================] - 0s 60us/step\n",
      "acc: 87.22%, loss: 0.34\n",
      "Confusion matrix:\n[[2194  126]\n [ 255  407]]\nMarco F1:0.800640\nMicro F1:0.872233\nWeighted F1:0.867065\n\n Evaluation of model trained from scratch:\n",
      "\r  32/2982 [..............................] - ETA: 4s",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1408/2982 [=============>................] - ETA: 0s",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2336/2982 [======================>.......] - ETA: 0s",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2982/2982 [==============================] - 0s 61us/step\n",
      "acc: 88.46%, loss: 0.29\n",
      "Confusion matrix:\n[[2216  104]\n [ 240  422]]\nMarco F1:0.819205\nMicro F1:0.884641\nWeighted F1:0.879681\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from src.data.preprocess.dataturks.preprocess_translearn_hatespeech import create_NN_sets\n",
    "from src.evaluation.hatespeech.evaluation_translearn_hatespeech import evaluate_best_model\n",
    "from src.models.hatespeech.model_translearn_hatespeech import fine_tune_model\n",
    "\n",
    "np.random.seed(42)\n",
    "vocab_size = 10000\n",
    "path_to_target_data = \"../../data/external/hatespeech/clean_sexism_dataset.csv\"\n",
    "path_to_original_model = \"../../models/example_dataturks.h5\"\n",
    "path_to_fine_tuned_model = \"../../models/fine_tuned.h5\"\n",
    "path_to_fine_tuned_model2 = \"../../models/fine_tuned_last_layer.h5\"\n",
    "path_to_sexist_model = \"../../models/zeerak_model.h5\"\n",
    "\n",
    "datasets = create_NN_sets(path_to_target_data, vocab_size)\n",
    "# fine_tune_model(path_to_original_model, path_to_fine_tuned_model, datasets)\n",
    "print(\"\\n Evaluation of model with ALL layers fine-tuned:\")\n",
    "evaluate_best_model(path_to_fine_tuned_model, datasets[4], datasets[5], datasets[6], 10000)\n",
    "\n",
    "# fine_tune_model(path_to_original_model, path_to_fine_tuned_model2, datasets)\n",
    "print(\"\\n Evaluation of model with LAST layer fine-tuned:\")\n",
    "evaluate_best_model(path_to_fine_tuned_model2, datasets[4], datasets[5], datasets[6], 10000)\n",
    "\n",
    "# train_model(path_to_sexist_model, datasets, vocab_size)\n",
    "print(\"\\n Evaluation of model trained from scratch:\")\n",
    "evaluate_best_model(path_to_sexist_model, datasets[4], datasets[5], datasets[6], 10000)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "pycharm-66275036",
   "language": "python",
   "display_name": "PyCharm (find-out)"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
