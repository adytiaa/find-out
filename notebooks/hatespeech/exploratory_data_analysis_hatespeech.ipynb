{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import networkx as nx\n",
    "\n",
    "from src.evaluation.hatespeech.evaluation_rulesbased_hatespeech import find_most_common_nouns\n",
    "\n",
    "data = pd.read_csv(\"../../data/external/hatespeech/hs_data.csv\")\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spacy_docs(data, label, misogynistic = True):\n",
    "    \"\"\" Returns a dataframe of spacy docs\n",
    "    Args:\n",
    "        \n",
    "    Returns:\n",
    "            \n",
    "    \"\"\"\n",
    "    if misogynistic:\n",
    "        return data.loc[data.loc[:,'annotation'] == \"misogynistic\", label].apply(lambda x: nlp(x))\n",
    "    else:\n",
    "        return data.loc[data.loc[:,'annotation'] == \"not_misogynistic\", label].apply(lambda x: nlp(x))\n",
    "\n",
    "\n",
    "misogyistic_docs = create_spacy_docs(data, \"normalize\", True)\n",
    "not_misogynistic_docs = create_spacy_docs(data, \"normalize\", False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_most_common_nouns(docs):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        \n",
    "    Returns:\n",
    "    \n",
    "    \"\"\"\n",
    "    return pd.DataFrame(find_most_common_nouns(docs), columns=['noun', 'count'])\n",
    "\n",
    "misogynistic_most_common_nouns = count_most_common_nouns(misogyistic_docs)\n",
    "not_misogyny_most_common_nouns = count_most_common_nouns(not_misogyistic_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_misogynistic = misogynistic_most_common_nouns.loc[0:10, :]\n",
    "top_10_not_misogynistic = not_misogyny_most_common_nouns.loc[0:10, :]\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, sharey=True, figsize=(15,15))\n",
    "m = sns.barplot(x=top_10_m['noun'], y=top_10_m['count'], ax=ax[0])\n",
    "nm = sns.barplot(x=top_10_nonm['noun'], y=top_10_nonm['count'], ax=ax[1])\n",
    "\n",
    "\n",
    "ax[0].set_title(\"Misogyny\")\n",
    "ax[1].set_title(\"Non Misogyny\")\n",
    "\n",
    "\n",
    "for item1, item2 in zip(m.get_xticklabels(), nm.get_xticklabels()):\n",
    "    item1.set_rotation(90)\n",
    "    item2.set_rotation(90)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tweet_length'] = data[\"text\"].apply(lambda tweet: len(tweet))\n",
    "data.groupby('annotation').mean()['tweet_length']\n",
    "\n",
    "sns.distplot(data.loc[data.loc[:,'annotation'] == 'misogynistic', \"tweet_length\"], kde=False, label=\"Misogynistic\")\n",
    "sns.distplot(data.loc[data.loc[:,'annotation'] == 'not_misogynistic', \"tweet_length\"], kde=False, label=\"Not misogynistic\")\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tweet_length'] = data[\"normalize\"].apply(lambda tweet: len(tweet))\n",
    "data.groupby('annotation').mean()['tweet_length']\n",
    "\n",
    "sns.distplot(data.loc[data.loc[:,'annotation'] == 'misogynistic', \"tweet_length\"], kde=False, label=\"Misogynistic\")\n",
    "sns.distplot(data.loc[data.loc[:,'annotation'] == 'not_misogynistic', \"tweet_length\"], kde=False, label=\"Not misogynistic\")\n",
    "\n",
    "plt.legend();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos(docs):\n",
    "    \n",
    "    tags = [token.tag_ for doc in docs for token in doc]\n",
    "    frequencies = [(word, tags.count(word)) for word in set(tags)]\n",
    "    return sorted(set(frequencies), key=lambda x: x[1], reverse = True)\n",
    "\n",
    "pos_misogyny = pd.DataFrame(pos(misogyny_docs), columns=['POS', 'count'])\n",
    "pos_nmisogyny = pd.DataFrame(pos(not_misogyny_docs), columns=['POS', 'count'])\n",
    "pos_misogyny_norm = pd.DataFrame(pos(misogyny_docs_norm), columns=['POS', 'count'])\n",
    "pos_nmisogyny_norm = pd.DataFrame(pos(not_misogyny_docs_norm), columns=['POS', 'count'])\n",
    "\n",
    "top_10_pos_m = pos_misogyny.loc[0:10, :]\n",
    "top_10_pos_nonm = pos_nmisogyny.loc[0:10, :]\n",
    "top_10_pos_m_norm = pos_misogyny_norm.loc[0:10, :]\n",
    "top_10_pos_nonm_norm = pos_nmisogyny_norm.loc[0:10, :]\n",
    "\n",
    "fig, ax = plt.subplots(ncols=4, sharey=True, figsize=(15,15))\n",
    "m = sns.barplot(x=top_10_pos_m['POS'], y=top_10_pos_m['count'], ax=ax[0])\n",
    "nm = sns.barplot(x=top_10_pos_nonm['POS'], y=top_10_pos_nonm['count'], ax=ax[1])\n",
    "m_norm = sns.barplot(x=top_10_pos_m_norm['POS'], y=top_10_pos_m_norm['count'], ax=ax[2])\n",
    "nm_norm = sns.barplot(x=top_10_pos_nonm_norm['POS'], y=top_10_pos_nonm_norm['count'], ax=ax[3])\n",
    "\n",
    "\n",
    "ax[0].set_title(\"Misogyny\")\n",
    "ax[1].set_title(\"Non Misogyny\")\n",
    "\n",
    "ax[2].set_title(\"Misogyny\")\n",
    "ax[3].set_title(\"Non Misogyny\")\n",
    "\n",
    "\n",
    "for item1, item2 in zip(m.get_xticklabels(), nm.get_xticklabels()):\n",
    "    item1.set_rotation(90)\n",
    "    item2.set_rotation(90)\n",
    "    \n",
    "\n",
    "for item1, item2 in zip(m_norm.get_xticklabels(), nm_norm.get_xticklabels()):\n",
    "    item1.set_rotation(90)\n",
    "    item2.set_rotation(90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dep(docs):\n",
    "    \n",
    "    tags = [token.dep_ for doc in docs for token in doc]\n",
    "    frequencies = [(word, tags.count(word)) for word in set(tags)]\n",
    "    return sorted(set(frequencies), key=lambda x: x[1], reverse = True)\n",
    "\n",
    "pos_misogyny = pd.DataFrame(dep(misogyny_docs), columns=['dependency', 'count'])\n",
    "pos_nmisogyny = pd.DataFrame(dep(not_misogyny_docs), columns=['dependency', 'count'])\n",
    "pos_misogyny_norm = pd.DataFrame(dep(misogyny_docs_norm), columns=['dependency', 'count'])\n",
    "pos_nmisogyny_norm = pd.DataFrame(dep(not_misogyny_docs_norm), columns=['dependency', 'count'])\n",
    "\n",
    "top_10_pos_m = pos_misogyny.loc[0:10, :]\n",
    "top_10_pos_nonm = pos_nmisogyny.loc[0:10, :]\n",
    "top_10_pos_m_norm = pos_misogyny_norm.loc[0:10, :]\n",
    "top_10_pos_nonm_norm = pos_nmisogyny_norm.loc[0:10, :]\n",
    "\n",
    "fig, ax = plt.subplots(ncols=4, sharey=True, figsize=(15,15))\n",
    "m = sns.barplot(x=top_10_pos_m['dependency'], y=top_10_pos_m['count'], ax=ax[0])\n",
    "nm = sns.barplot(x=top_10_pos_nonm['dependency'], y=top_10_pos_nonm['count'], ax=ax[1])\n",
    "m_norm = sns.barplot(x=top_10_pos_m_norm['dependency'], y=top_10_pos_m_norm['count'], ax=ax[2])\n",
    "nm_norm = sns.barplot(x=top_10_pos_nonm_norm['dependency'], y=top_10_pos_nonm_norm['count'], ax=ax[3])\n",
    "\n",
    "\n",
    "ax[0].set_title(\"Misogyny\")\n",
    "ax[1].set_title(\"Non Misogyny\")\n",
    "\n",
    "ax[2].set_title(\"Misogyny\")\n",
    "ax[3].set_title(\"Non Misogyny\")\n",
    "\n",
    "\n",
    "for item1, item2 in zip(m.get_xticklabels(), nm.get_xticklabels()):\n",
    "    item1.set_rotation(90)\n",
    "    item2.set_rotation(90)\n",
    "    \n",
    "\n",
    "for item1, item2 in zip(m_norm.get_xticklabels(), nm_norm.get_xticklabels()):\n",
    "    item1.set_rotation(90)\n",
    "    item2.set_rotation(90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bigrams\n",
    "for doc in misogyny_docs:\n",
    "    for noun_phrase in list(doc.noun_chunks):\n",
    "        noun_phrase.merge(noun_phrase.root.tag_, noun_phrase.root.lemma_, noun_phrase.root.ent_type_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(token.text,token.pos_) for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_deptree_into_graph(tweet):\n",
    "    \"\"\"\n",
    "   \n",
    "    \"\"\"\n",
    "    edges = []\n",
    "    for token in tweet:\n",
    "        for child in token.children:\n",
    "            edges.append((f'{token.lower_}',\n",
    "                          f'{child.lower_}'))\n",
    "    return nx.Graph(edges)\n",
    "    \n",
    "edges = []\n",
    "for doc in misogyny_docs:\n",
    "    graph = load_deptree_into_graph(doc)\n",
    "    edges+=list(graph.edges)\n",
    "    \n",
    "df = pd.DataFrame(edges, columns = ['e1', 'e2'])\n",
    "nouns = df['e1'].to_list()\n",
    "frequencies = [(word, nouns.count(word)) for word in set(nouns)]\n",
    "sorted(set(frequencies), key=lambda x: x[1], reverse = True)\n",
    "df.loc[df.loc[:, \"e1\"] == \"feminazi\"]['e2']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (find-out)",
   "language": "python",
   "name": "pycharm-66275036"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
